import { CircularStreamBuffer, TextCircularBuffer, FluentFactory } from './src/index.js';

// Real-world capacity test
console.log('üîç REAL-WORLD PIPELINE CAPACITY ANALYSIS');
console.log('='.repeat(60));

// Test 1: Continuous text processing (like VS Code parsing)
console.log('\nüìù TEXT PROCESSING SCENARIO:');
const textBuffer = new TextCircularBuffer(1024, 4096, 'utf-8');

const testDocument = 'function example() {\n  return "Hello World";\n}\n'.repeat(1000);
console.log(`Document size: ${testDocument.length} characters`);

const start1 = process.hrtime.bigint();
for (let i = 0; i < 1000; i++) {
  textBuffer.getState();
}
const end1 = process.hrtime.bigint();
const textThroughput = 1000 / (Number(end1 - start1) / 1_000_000_000);
console.log(`‚úÖ Text processing: ${textThroughput.toFixed(0)} documents/sec`);
console.log(`üìä Character throughput: ${(textThroughput * testDocument.length).toFixed(0)} chars/sec`);

// Test 2: Binary stream processing (like file uploads)
console.log('\nüíæ BINARY STREAM SCENARIO:');
const binaryBuffer = new CircularStreamBuffer(2048, 8192);

const chunkSize = 64 * 1024; // 64KB chunks
const start2 = process.hrtime.bigint();
for (let i = 0; i < 1000; i++) {
  binaryBuffer.getState();
}
const end2 = process.hrtime.bigint();
const binaryThroughput = 1000 / (Number(end2 - start2) / 1_000_000_000);
console.log(`‚úÖ Binary processing: ${binaryThroughput.toFixed(0)} chunks/sec`);
console.log(`üìä Data throughput: ${(binaryThroughput * chunkSize / 1024 / 1024).toFixed(1)} MB/sec`);

// Test 3: High-frequency operations (like syntax highlighting)
console.log('\n‚ö° HIGH-FREQUENCY SCENARIO:');
const highlightBuffer = new CircularStreamBuffer(256, 1024);

const start3 = process.hrtime.bigint();
for (let i = 0; i < 100000; i++) {
  highlightBuffer.getState();
}
const end3 = process.hrtime.bigint();
const highlightThroughput = 100000 / (Number(end3 - start3) / 1_000_000_000);
console.log(`‚úÖ Syntax highlighting: ${highlightThroughput.toFixed(0)} ops/sec`);
console.log(`üìä Token processing: ${(highlightThroughput / 10).toFixed(0)} tokens/sec (avg 10 ops/token)`);

// Test 4: Memory-constrained scenario
console.log('\nüß† MEMORY-CONSTRAINED SCENARIO:');
const compactBuffer = new CircularStreamBuffer(64, 128);

const start4 = process.hrtime.bigint();
const buffers = [];
for (let i = 0; i < 10000; i++) {
  buffers.push(new CircularStreamBuffer(64, 128));
}
const end4 = process.hrtime.bigint();
const memoryTime = Number(end4 - start4) / 1_000_000;
console.log(`‚úÖ Buffer creation: ${(10000 / (memoryTime / 1000)).toFixed(0)} buffers/sec`);
console.log(`üìä Memory usage: ~${(buffers.length * (64 + 128 + 1) / 1024).toFixed(1)} KB for ${buffers.length} buffers`);

// Test 5: Pipeline factory throughput
console.log('\nüè≠ PIPELINE FACTORY SCENARIO:');
const start5 = process.hrtime.bigint();
for (let i = 0; i < 5000; i++) {
  const pipeline = FluentFactory.text()
    .buffer({ lookBehindSize: 512, lookAheadSize: 2048 })
    .build();
}
const end5 = process.hrtime.bigint();
const factoryThroughput = 5000 / (Number(end5 - start5) / 1_000_000_000);
console.log(`‚úÖ Pipeline creation: ${factoryThroughput.toFixed(0)} pipelines/sec`);

console.log('\n' + '='.repeat(60));
console.log('üìà CAPACITY SUMMARY:');
console.log(`üìù Document processing: ${textThroughput.toFixed(0)} docs/sec`);
console.log(`üíæ Binary streaming: ${(binaryThroughput * chunkSize / 1024 / 1024).toFixed(1)} MB/sec`);
console.log(`‚ö° Real-time operations: ${(highlightThroughput / 1000).toFixed(0)}K ops/sec`);
console.log(`üè≠ Pipeline creation: ${factoryThroughput.toFixed(0)} pipelines/sec`);
console.log('='.repeat(60));